{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%reset -f                        # clear all variables from the workspace\n",
    "'generic imports'\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "from src import utils   \n",
    "import datetime        \n",
    "\n",
    "'machine learning imports'\n",
    "import torch\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "from pytorch_tabnet.pretraining import TabNetPretrainer\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu\n"
     ]
    }
   ],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"Using {}\".format(DEVICE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.abspath('../data')\n",
    "\n",
    "# Non-augmented dataset\n",
    "df_train = pd.read_csv(os.path.join(data_dir, 'EdgeIIot_train_100k.csv'), low_memory=False)\n",
    "AUGMENTATION = 'None'\n",
    "\n",
    "# SMOTE augmented dataset\n",
    "# df_train = pd.read_csv(os.path.join(data_dir, 'EdgeIIot_train_100k_SMOTE.csv'), low_memory=False)\n",
    "# AUGMENTATION = 'SMOTE'\n",
    "\n",
    "# SMOTE-NC augmented dataset\n",
    "# df_train = pd.read_csv(os.path.join(data_dir, 'EdgeIIot_train_100k_SMOTE_NC.csv'), low_memory=False)\n",
    "# AUGMENTATION = 'SMOTE-NC'\n",
    "\n",
    "# RealTabFormer augmentation dataset\n",
    "# df_train = pd.read_csv(os.path.join(data_dir, 'EdgeIIot_train_100k_RealTabFormer.csv'), low_memory=False)\n",
    "# AUGMENTATION = 'RealTabFormer'\n",
    "\n",
    "# GReaT augmentation dataset\n",
    "# df_train = pd.read_csv(os.path.join(data_dir, 'EdgeIIot_train_100k_GReaT.csv'), low_memory=False)\n",
    "# AUGMENTATION = 'GReaT'\n",
    "\n",
    "\n",
    "# Test data for all datasets\n",
    "df_test = pd.read_csv(os.path.join(data_dir, 'EdgeIIot_test.csv'), low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (536515, 44), y_train shape: (536515,)\n",
      "X_test shape: (381934, 44), y_test shape: (381934,)\n",
      "[6, 7, 8, 25, 31, 39, 40]\n"
     ]
    }
   ],
   "source": [
    "# drop columns mbtcp.unit_id and mbtcp.trans_id from train and test data    \n",
    "df_train = df_train.drop(['mbtcp.unit_id', 'mbtcp.trans_id'], axis=1)\n",
    "df_test = df_test.drop(['mbtcp.unit_id', 'mbtcp.trans_id'], axis=1)\n",
    "\n",
    "# extract features from df_train\n",
    "features = [col for col in df_train.columns if col not in [\"Attack_label\"]+[\"Attack_type\"]] \n",
    "\n",
    "# index of categorical features in df_train\n",
    "cat_idxs = [i for i, f in enumerate(features) if f in df_train.select_dtypes(include=\"object\").columns]\n",
    "\n",
    "# number of unique values in each categorical column\n",
    "cat_dims = [len(df_train[f].unique()) for i, f in enumerate(features) if f in df_train.select_dtypes(include=\"object\").columns]\n",
    "\n",
    "# AQUI Categorical columns in df_train\n",
    "categorical_columns = [f for f in features if f in df_train.select_dtypes(include=\"object\").columns]\n",
    "\n",
    "X_train_encoded = pd.get_dummies(X_train, columns=categorical_columns)\n",
    "\n",
    "\n",
    "# converts X_train and y_train to numpy arrays\n",
    "X_train = df_train[features]\n",
    "y_train = df_train[\"Attack_type\"]\n",
    "\n",
    "# converts X_test and y_test to numpy arrays\n",
    "X_test = df_test[features]\n",
    "y_test = df_test[\"Attack_type\"]\n",
    "\n",
    "# size of X_train, y_train  X_test, y_test\n",
    "print(f'X_train shape: {X_train.shape}, y_train shape: {y_train.shape}')\n",
    "print(f'X_test shape: {X_test.shape}, y_test shape: {y_test.shape}')\n",
    "print(cat_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arp.opcode</th>\n",
       "      <th>arp.hw.size</th>\n",
       "      <th>icmp.checksum</th>\n",
       "      <th>icmp.seq_le</th>\n",
       "      <th>icmp.unused</th>\n",
       "      <th>http.content_length</th>\n",
       "      <th>http.request.method</th>\n",
       "      <th>http.referer</th>\n",
       "      <th>http.request.version</th>\n",
       "      <th>http.response</th>\n",
       "      <th>...</th>\n",
       "      <th>mqtt.hdrflags</th>\n",
       "      <th>mqtt.len</th>\n",
       "      <th>mqtt.msg_decoded_as</th>\n",
       "      <th>mqtt.msgtype</th>\n",
       "      <th>mqtt.proto_len</th>\n",
       "      <th>mqtt.protoname</th>\n",
       "      <th>mqtt.topic</th>\n",
       "      <th>mqtt.topic_len</th>\n",
       "      <th>mqtt.ver</th>\n",
       "      <th>mbtcp.len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536510</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536511</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536512</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536513</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536514</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>536515 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        arp.opcode  arp.hw.size  icmp.checksum  icmp.seq_le  icmp.unused  \\\n",
       "0              0.0          0.0            0.0          0.0          0.0   \n",
       "1              0.0          0.0            0.0          0.0          0.0   \n",
       "2              0.0          0.0            0.0          0.0          0.0   \n",
       "3              0.0          0.0            0.0          0.0          0.0   \n",
       "4              0.0          0.0            0.0          0.0          0.0   \n",
       "...            ...          ...            ...          ...          ...   \n",
       "536510         0.0          0.0            0.0          0.0          0.0   \n",
       "536511         0.0          0.0            0.0          0.0          0.0   \n",
       "536512         0.0          0.0            0.0          0.0          0.0   \n",
       "536513         0.0          0.0            0.0          0.0          0.0   \n",
       "536514         0.0          0.0            0.0          0.0          0.0   \n",
       "\n",
       "        http.content_length http.request.method http.referer  \\\n",
       "0                       0.0                 0.0          0.0   \n",
       "1                       0.0                   0          0.0   \n",
       "2                       0.0                 0.0          0.0   \n",
       "3                       0.0                 0.0          0.0   \n",
       "4                       0.0                   0          0.0   \n",
       "...                     ...                 ...          ...   \n",
       "536510                  0.0                 0.0          0.0   \n",
       "536511                  0.0                 0.0          0.0   \n",
       "536512                  0.0                 0.0          0.0   \n",
       "536513                  0.0                 0.0          0.0   \n",
       "536514                  0.0                 0.0          0.0   \n",
       "\n",
       "       http.request.version  http.response  ...  mqtt.hdrflags  mqtt.len  \\\n",
       "0                       0.0            0.0  ...            0.0       0.0   \n",
       "1                         0            0.0  ...            0.0       0.0   \n",
       "2                       0.0            0.0  ...            0.0       0.0   \n",
       "3                       0.0            0.0  ...            0.0       0.0   \n",
       "4                         0            0.0  ...            0.0       0.0   \n",
       "...                     ...            ...  ...            ...       ...   \n",
       "536510                  0.0            0.0  ...            0.0       0.0   \n",
       "536511                  0.0            0.0  ...            0.0       0.0   \n",
       "536512                  0.0            0.0  ...            0.0       0.0   \n",
       "536513                  0.0            0.0  ...            0.0       0.0   \n",
       "536514                  0.0            0.0  ...            0.0       0.0   \n",
       "\n",
       "        mqtt.msg_decoded_as  mqtt.msgtype  mqtt.proto_len  mqtt.protoname  \\\n",
       "0                       0.0           0.0             0.0             0.0   \n",
       "1                       0.0           0.0             0.0             0.0   \n",
       "2                       0.0           0.0             0.0             0.0   \n",
       "3                       0.0           0.0             0.0             0.0   \n",
       "4                       0.0           0.0             0.0             0.0   \n",
       "...                     ...           ...             ...             ...   \n",
       "536510                  0.0           0.0             0.0               0   \n",
       "536511                  0.0           0.0             0.0               0   \n",
       "536512                  0.0           0.0             0.0               0   \n",
       "536513                  0.0           0.0             0.0               0   \n",
       "536514                  0.0           0.0             0.0               0   \n",
       "\n",
       "        mqtt.topic  mqtt.topic_len  mqtt.ver  mbtcp.len  \n",
       "0              0.0             0.0       0.0        0.0  \n",
       "1              0.0             0.0       0.0        0.0  \n",
       "2              0.0             0.0       0.0        0.0  \n",
       "3              0.0             0.0       0.0        0.0  \n",
       "4              0.0             0.0       0.0        0.0  \n",
       "...            ...             ...       ...        ...  \n",
       "536510           0             0.0       0.0        0.0  \n",
       "536511           0             0.0       0.0        0.0  \n",
       "536512           0             0.0       0.0        0.0  \n",
       "536513           0             0.0       0.0        0.0  \n",
       "536514           0             0.0       0.0        0.0  \n",
       "\n",
       "[536515 rows x 44 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack_type and encoded labels:\n",
      "\n",
      "Backdoor                0\n",
      "DDoS_HTTP               1\n",
      "DDoS_ICMP               2\n",
      "DDoS_TCP                3\n",
      "DDoS_UDP                4\n",
      "Fingerprinting          5\n",
      "MITM                    6\n",
      "Normal                  7\n",
      "Password                8\n",
      "Port_Scanning           9\n",
      "Ransomware              10\n",
      "SQL_injection           11\n",
      "Uploading               12\n",
      "Vulnerability_scanner   13\n",
      "XSS                     14\n"
     ]
    }
   ],
   "source": [
    "# instantiate the label encoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# fit and encode the training labels\n",
    "y_train = le.fit_transform(y_train)\n",
    "\n",
    "# encode the test labels\n",
    "y_test = le.transform(y_test)\n",
    "\n",
    "print('Attack_type and encoded labels:\\n')\n",
    "for i, label in enumerate(le.classes_):\n",
    "    print(f'{label:23s} {i:d}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # embedding dimension for each categorical column\n",
    "# cat_emb_dim = 10 \n",
    "\n",
    "# # initialize embedder \n",
    "# cat_embedder = TabNetPretrainer(cat_dims, cat_emb_dim, cat_idxs)\n",
    "\n",
    "# # instantiate TabNetClassifier model\n",
    "# tabnet = TabNetClassifier(device_name = DEVICE,\n",
    "#                           cat_idxs=cat_idxs,\n",
    "#                           cat_dims=cat_dims,\n",
    "#                           cat_emb_dim=cat_emb_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 7, 8, 25, 31, 39, 40]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from X_train extract indices of categorical columns\n",
    "cat_idxs = [i for i, f in enumerate(features) if f in X_train.select_dtypes(include=\"object\").columns]\n",
    "cat_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ambientes_virtuais_py\\data_augment\\data_augment\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    }
   ],
   "source": [
    "tabnet = TabNetClassifier(\n",
    "    n_d=64, n_a=64, n_steps=5,\n",
    "    gamma=1.5, n_independent=2, n_shared=2,\n",
    "    cat_idxs=cat_idxs,\n",
    "    cat_dims=cat_dims,\n",
    "    cat_emb_dim=10,\n",
    "    lambda_sparse=1e-4, momentum=0.3, clip_value=2.,\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params=dict(lr=2e-2),\n",
    "    scheduler_params = {\"gamma\": 0.95, \"step_size\": 20},\n",
    "    scheduler_fn=torch.optim.lr_scheduler.StepLR, epsilon=1e-15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'GET'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\ambientes_virtuais_py\\data_augment\\tabular_data_augmentation\\tabular_data_augmentation\\notebooks\\3_tabnet_evaluation.ipynb Cell 15\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/ambientes_virtuais_py/data_augment/tabular_data_augmentation/tabular_data_augmentation/notebooks/3_tabnet_evaluation.ipynb#X34sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m tabnet\u001b[39m.\u001b[39;49mfit(X_train\u001b[39m=\u001b[39;49mX_train\u001b[39m.\u001b[39;49mvalues, y_train\u001b[39m=\u001b[39;49my_train,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/ambientes_virtuais_py/data_augment/tabular_data_augmentation/tabular_data_augmentation/notebooks/3_tabnet_evaluation.ipynb#X34sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m            augmentations\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/ambientes_virtuais_py/data_augment/tabular_data_augmentation/tabular_data_augmentation/notebooks/3_tabnet_evaluation.ipynb#X34sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m            max_epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/ambientes_virtuais_py/data_augment/tabular_data_augmentation/tabular_data_augmentation/notebooks/3_tabnet_evaluation.ipynb#X34sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m            patience\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/ambientes_virtuais_py/data_augment/tabular_data_augmentation/tabular_data_augmentation/notebooks/3_tabnet_evaluation.ipynb#X34sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m            batch_size\u001b[39m=\u001b[39;49m\u001b[39m1024\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/ambientes_virtuais_py/data_augment/tabular_data_augmentation/tabular_data_augmentation/notebooks/3_tabnet_evaluation.ipynb#X34sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m            virtual_batch_size\u001b[39m=\u001b[39;49m\u001b[39m128\u001b[39;49m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/ambientes_virtuais_py/data_augment/tabular_data_augmentation/tabular_data_augmentation/notebooks/3_tabnet_evaluation.ipynb#X34sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m            )\n",
      "File \u001b[1;32mc:\\ambientes_virtuais_py\\data_augment\\data_augment\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:217\u001b[0m, in \u001b[0;36mTabModel.fit\u001b[1;34m(self, X_train, y_train, eval_set, eval_name, eval_metric, loss_fn, weights, max_epochs, patience, batch_size, virtual_batch_size, num_workers, drop_last, callbacks, pin_memory, from_unsupervised, warm_start, augmentations, compute_importance)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    215\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss_fn \u001b[39m=\u001b[39m loss_fn\n\u001b[1;32m--> 217\u001b[0m check_input(X_train)\n\u001b[0;32m    218\u001b[0m check_warm_start(warm_start, from_unsupervised)\n\u001b[0;32m    220\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdate_fit_params(\n\u001b[0;32m    221\u001b[0m     X_train,\n\u001b[0;32m    222\u001b[0m     y_train,\n\u001b[0;32m    223\u001b[0m     eval_set,\n\u001b[0;32m    224\u001b[0m     weights,\n\u001b[0;32m    225\u001b[0m )\n",
      "File \u001b[1;32mc:\\ambientes_virtuais_py\\data_augment\\data_augment\\lib\\site-packages\\pytorch_tabnet\\utils.py:507\u001b[0m, in \u001b[0;36mcheck_input\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m    505\u001b[0m     err_message \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mPandas DataFrame are not supported: apply X.values when calling fit\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    506\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(err_message)\n\u001b[1;32m--> 507\u001b[0m check_array(X, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\ambientes_virtuais_py\\data_augment\\data_augment\\lib\\site-packages\\sklearn\\utils\\validation.py:915\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    913\u001b[0m         array \u001b[39m=\u001b[39m xp\u001b[39m.\u001b[39mastype(array, dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    914\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 915\u001b[0m         array \u001b[39m=\u001b[39m _asarray_with_order(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype, xp\u001b[39m=\u001b[39;49mxp)\n\u001b[0;32m    916\u001b[0m \u001b[39mexcept\u001b[39;00m ComplexWarning \u001b[39mas\u001b[39;00m complex_warning:\n\u001b[0;32m    917\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    918\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mComplex data not supported\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[0;32m    919\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ambientes_virtuais_py\\data_augment\\data_augment\\lib\\site-packages\\sklearn\\utils\\_array_api.py:380\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    378\u001b[0m     array \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39marray(array, order\u001b[39m=\u001b[39morder, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[0;32m    379\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 380\u001b[0m     array \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39;49masarray(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m    382\u001b[0m \u001b[39m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[39m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[0;32m    384\u001b[0m \u001b[39mreturn\u001b[39;00m xp\u001b[39m.\u001b[39masarray(array)\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'GET'"
     ]
    }
   ],
   "source": [
    "tabnet.fit(X_train=X_train.values, y_train=y_train,\n",
    "           augmentations=None,\n",
    "           max_epochs=100, \n",
    "           patience=10,\n",
    "           batch_size=1024,\n",
    "           virtual_batch_size=128\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 8, 4, ..., 7, 7, 7])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0, 0.0, 0.0, ..., 0.0, 0.0, 0.0],\n",
       "       [0.0, 0.0, 0.0, ..., 0.0, 0.0, 0.0],\n",
       "       [0.0, 0.0, 0.0, ..., 0.0, 0.0, 0.0],\n",
       "       ...,\n",
       "       [0.0, 0.0, 0.0, ..., 0.0, 0.0, 0.0],\n",
       "       [0.0, 0.0, 0.0, ..., 0.0, 0.0, 0.0],\n",
       "       [0.0, 0.0, 0.0, ..., 0.0, 0.0, 0.0]], dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = TabNetClassifier(\n",
    "    n_d=64, n_a=64, n_steps=5,\n",
    "    gamma=1.5, n_independent=2, n_shared=2,\n",
    "    cat_idxs=cat_idxs,\n",
    "    cat_dims=cat_dims,\n",
    "    cat_emb_dim=cat_emb_dim,\n",
    "    lambda_sparse=1e-4, momentum=0.3, clip_value=2.,\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params=dict(lr=2e-2),\n",
    "    scheduler_params = {\"gamma\": 0.95, \"step_size\": 20},\n",
    "    scheduler_fn=torch.optim.lr_scheduler.StepLR, epsilon=1e-15\n",
    ")\n",
    "\n",
    "max_epochs = 100 if not os.getenv(\"CI\", False) else 2\n",
    "\n",
    "clf.fit(\n",
    "    X_train=X_train, y_train=y_train,\n",
    "    max_epochs=max_epochs, patience=100,\n",
    "    batch_size=16384, virtual_batch_size=256\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_filename = tabnet.save_model('checkpoints/tabnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = tabnet.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculare and printe a nice board with precision, Recall, F1-score, AUC, Accuracy without classificaiton report\n",
    "print(\"Model Evaluation Metrics\")\n",
    "print(\"~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "print(\"Accuracy: {}\".format(metrics.accuracy_score(y_test, predictions)))\n",
    "print(\"Precision: {}\".format(metrics.precision_score(y_test, predictions, average='weighted')))\n",
    "print(\"Recall: {}\".format(metrics.recall_score(y_test, predictions, average='weighted')))\n",
    "print(\"F1: {}\".format(metrics.f1_score(y_test, predictions, average='weighted')))\n",
    "print(\"AUC: {}\".format(metrics.roc_auc_score(y_test, predictions, average='weighted')))\n",
    "print(\"~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat = metrics.confusion_matrix(y_test, predictions)\n",
    "# Attack_type: ['DDoS_UDP' 'Password' 'DDoS_TCP' 'Backdoor' 'DDoS_ICMP' 'Port_Scanning'\n",
    "#  'Vulnerability_scanner' 'SQL_injection' 'DDoS_HTTP' 'Uploading' 'XSS'\n",
    "#  'Ransomware' 'MITM' 'Fingerprinting' 'Normal']\n",
    "\n",
    "# conf_mat_df = pd.DataFrame(conf_mat, index = ['DDoS_UDP', 'Password', 'DDoS_TCP', 'Backdoor', 'DDoS_ICMP', 'Port_Scanning', 'Vulnerability_scanner', 'SQL_injection', 'DDoS_HTTP', 'Uploading', 'XSS', 'Ransomware', 'MITM', 'Fingerprinting', 'Normal'], columns = ['DDoS_UDP', 'Password', 'DDoS_TCP', 'Backdoor', 'DDoS_ICMP', 'Port_Scanning', 'Vulnerability_scanner', 'SQL_injection', 'DDoS_HTTP', 'Uploading', 'XSS', 'Ransomware', 'MITM', 'Fingerprinting', 'Normal'])\n",
    "\n",
    "conf_mat_df.index.name = 'Actual'\n",
    "conf_mat_df.columns.name = 'Predicted'\n",
    "print(conf_mat_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary for results\n",
    "results = {\n",
    "    \"model\": \"TabNet\",\n",
    "    \"augmentations\": AUGMENTATION,\n",
    "    \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    \"accuracy\": metrics.accuracy_score(y_test, predictions),\n",
    "    \"precision\": metrics.precision_score(y_test, predictions, average='weighted'),\n",
    "    \"recall\": metrics.recall_score(y_test, predictions, average='weighted'),\n",
    "    \"f1\": metrics.f1_score(y_test, predictions, average='weighted'),\n",
    "    \"auc\": metrics.roc_auc_score(y_test, predictions, average='weighted')\n",
    "    }\n",
    "\n",
    "# save results to csv   \n",
    "utils.save_results([results], 'results/TabNet.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_augment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
