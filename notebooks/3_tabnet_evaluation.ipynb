{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "'generic imports'\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "from src import utils\n",
    "\n",
    "'machine learning imports'\n",
    "import torch\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "from pytorch_tabnet.pretraining import TabNetPretrainer\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu\n"
     ]
    }
   ],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"Using {}\".format(DEVICE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.abspath('../data')\n",
    "\n",
    "# Non-augmented dataset\n",
    "df_train = pd.read_csv(os.path.join(data_dir, 'EdgeIIot_train_100k.csv'), low_memory=False)\n",
    "AUGMENTATION = 'None'\n",
    "\n",
    "# SMOTE augmented dataset\n",
    "# df_train = pd.read_csv(os.path.join(data_dir, 'EdgeIIot_train_100k_SMOTE.csv'), low_memory=False)\n",
    "# AUGMENTATION = 'SMOTE'\n",
    "\n",
    "# SMOTE-NC augmented dataset\n",
    "# df_train = pd.read_csv(os.path.join(data_dir, 'EdgeIIot_train_100k_SMOTE_NC.csv'), low_memory=False)\n",
    "# AUGMENTATION = 'SMOTE-NC'\n",
    "\n",
    "# RealTabFormer augmentation dataset\n",
    "# df_train = pd.read_csv(os.path.join(data_dir, 'EdgeIIot_train_100k_RealTabFormer.csv'), low_memory=False)\n",
    "# AUGMENTATION = 'RealTabFormer'\n",
    "\n",
    "# GReaT augmentation dataset\n",
    "# df_train = pd.read_csv(os.path.join(data_dir, 'EdgeIIot_train_100k_GReaT.csv'), low_memory=False)\n",
    "# AUGMENTATION = 'GReaT'\n",
    "\n",
    "\n",
    "# Test data for all datasets\n",
    "df_test = pd.read_csv(os.path.join(data_dir, 'EdgeIIot_test.csv'), low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns mbtcp.unit_id and mbtcp.trans_id from train and test data    \n",
    "df_train = df_train.drop(['mbtcp.unit_id', 'mbtcp.trans_id'], axis=1)\n",
    "df_test = df_test.drop(['mbtcp.unit_id', 'mbtcp.trans_id'], axis=1)\n",
    "\n",
    "# extract features from df_train\n",
    "features = [col for col in df_train.columns if col not in [\"Attack_label\"]+[\"Attack_type\"]] \n",
    "\n",
    "# index of categorical features in df_train\n",
    "cat_idxs = [i for i, f in enumerate(features) if f in df_train.select_dtypes(include=\"object\").columns]\n",
    "\n",
    "# number of unique values in each categorical column\n",
    "cat_dims = [len(df_train[f].unique()) for i, f in enumerate(features) if f in df_train.select_dtypes(include=\"object\").columns]\n",
    "\n",
    "# converts X_train and y_train to numpy arrays\n",
    "X_train = df_train[features].values\n",
    "y_train = df_train[\"Attack_type\"].values\n",
    "\n",
    "# converts X_test and y_test to numpy arrays\n",
    "X_test = df_test[features].values\n",
    "y_test = df_test[\"Attack_type\"].values\n",
    "\n",
    "# size of X_train, y_train  X_test, y_test\n",
    "print(f'X_train shape: {X_train.shape}, y_train shape: {y_train.shape}')\n",
    "print(f'X_test shape: {X_test.shape}, y_test shape: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ambientes_virtuais_py\\data_augment\\data_augment\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    }
   ],
   "source": [
    "# embedding dimension for each categorical column\n",
    "cat_emb_dim = 10 \n",
    "\n",
    "# initialize embedder \n",
    "cat_embedder = TabNetPretrainer(cat_dims, cat_emb_dim, cat_idxs)\n",
    "\n",
    "# instantiate TabNetClassifier model\n",
    "tabnet = TabNetClassifier(device_name = DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabnet.fit(X_train=X_train, y_train=y_train,\n",
    "           augmentations=None,\n",
    "           max_epochs=100, \n",
    "           patience=10,\n",
    "           batch_size=1024,\n",
    "           virtual_batch_size=128,\n",
    "           cat_emb_dim=cat_emb_dim,\n",
    "           cat_idxs=cat_idxs,\n",
    "           cat_dims=cat_dims,\n",
    "           pretraining_ratio=0.5,\n",
    "           pretrainer=cat_embedder,\n",
    "           )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_filename = tabnet.save_model('checkpoints/tabnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = tabnet.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculare and printe a nice board with precision, Recall, F1-score, AUC, Accuracy without classificaiton report\n",
    "print(\"Model Evaluation Metrics\")\n",
    "print(\"~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "print(\"Accuracy: {}\".format(metrics.accuracy_score(y_test, predictions)))\n",
    "print(\"Precision: {}\".format(metrics.precision_score(y_test, predictions, average='weighted')))\n",
    "print(\"Recall: {}\".format(metrics.recall_score(y_test, predictions, average='weighted')))\n",
    "print(\"F1: {}\".format(metrics.f1_score(y_test, predictions, average='weighted')))\n",
    "print(\"AUC: {}\".format(metrics.roc_auc_score(y_test, predictions, average='weighted')))\n",
    "print(\"~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat = metrics.confusion_matrix(y_test, predictions)\n",
    "# Attack_type: ['DDoS_UDP' 'Password' 'DDoS_TCP' 'Backdoor' 'DDoS_ICMP' 'Port_Scanning'\n",
    "#  'Vulnerability_scanner' 'SQL_injection' 'DDoS_HTTP' 'Uploading' 'XSS'\n",
    "#  'Ransomware' 'MITM' 'Fingerprinting' 'Normal']\n",
    "\n",
    "# conf_mat_df = pd.DataFrame(conf_mat, index = ['DDoS_UDP', 'Password', 'DDoS_TCP', 'Backdoor', 'DDoS_ICMP', 'Port_Scanning', 'Vulnerability_scanner', 'SQL_injection', 'DDoS_HTTP', 'Uploading', 'XSS', 'Ransomware', 'MITM', 'Fingerprinting', 'Normal'], columns = ['DDoS_UDP', 'Password', 'DDoS_TCP', 'Backdoor', 'DDoS_ICMP', 'Port_Scanning', 'Vulnerability_scanner', 'SQL_injection', 'DDoS_HTTP', 'Uploading', 'XSS', 'Ransomware', 'MITM', 'Fingerprinting', 'Normal'])\n",
    "\n",
    "conf_mat_df.index.name = 'Actual'\n",
    "conf_mat_df.columns.name = 'Predicted'\n",
    "print(conf_mat_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary for results\n",
    "results = {\n",
    "    \"model\": \"TabNet\",\n",
    "    \"augmentations\": AUGMENTATION,\n",
    "    \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    \"accuracy\": metrics.accuracy_score(y_test, predictions),\n",
    "    \"precision\": metrics.precision_score(y_test, predictions, average='weighted'),\n",
    "    \"recall\": metrics.recall_score(y_test, predictions, average='weighted'),\n",
    "    \"f1\": metrics.f1_score(y_test, predictions, average='weighted'),\n",
    "    \"auc\": metrics.roc_auc_score(y_test, predictions, average='weighted')\n",
    "    }\n",
    "\n",
    "# save results to csv   \n",
    "utils.save_results([results], 'results/TabNet.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_augment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
