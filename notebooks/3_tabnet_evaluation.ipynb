{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/tiagociic/Projectos/inovmineral/project/notebooks/3_tabnet_evaluation.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/tiagociic/Projectos/inovmineral/project/notebooks/3_tabnet_evaluation.ipynb#W1sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m        \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tiagociic/Projectos/inovmineral/project/notebooks/3_tabnet_evaluation.ipynb#W1sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m'\u001b[39m\u001b[39mmachine learning imports\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/tiagociic/Projectos/inovmineral/project/notebooks/3_tabnet_evaluation.ipynb#W1sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tiagociic/Projectos/inovmineral/project/notebooks/3_tabnet_evaluation.ipynb#W1sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_tabnet\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtab_model\u001b[39;00m \u001b[39mimport\u001b[39;00m TabNetClassifier\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tiagociic/Projectos/inovmineral/project/notebooks/3_tabnet_evaluation.ipynb#W1sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpytorch_tabnet\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpretraining\u001b[39;00m \u001b[39mimport\u001b[39;00m TabNetPretrainer\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "%reset -f                        # clear all variables from the workspace\n",
    "'generic imports'\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "from src import utils   \n",
    "import datetime\n",
    "import numpy as np        \n",
    "\n",
    "'machine learning imports'\n",
    "import torch\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "from pytorch_tabnet.pretraining import TabNetPretrainer\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/tiagociic/Projectos/inovmineral/project/notebooks/3_tabnet_evaluation.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/tiagociic/Projectos/inovmineral/project/notebooks/3_tabnet_evaluation.ipynb#X45sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n",
      "Total GPU memory: 7.8 GB | Current usage: 0.0 GB\n"
     ]
    }
   ],
   "source": [
    "DEVICE = 'CUDA' if torch.cuda.is_available() else 'CPU'\n",
    "print(\"Using {}\".format(DEVICE))\n",
    "\n",
    "# Info on the device available memory\n",
    "if DEVICE == 'CUDA':\n",
    "    \n",
    "    gpu = torch.device('cuda')\n",
    "    total_memory = torch.cuda.get_device_properties(gpu).total_memory / 1024**3\n",
    "    current_memory = torch.cuda.memory_allocated(gpu) / 1024**3\n",
    "\n",
    "    print(f'Total GPU memory: {total_memory:.1f} GB | Current usage: {current_memory:.1f} GB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.abspath('../data')\n",
    "\n",
    "# Set the desired option ('None', 'SMOTE', 'SMOTE-NC', 'RealTabFormer', 'GReaT')\n",
    "AUGMENTATION = 'None'\n",
    "# Conditional structure to load the appropriate dataset based on the AUGMENTATION option\n",
    "if AUGMENTATION == 'None':\n",
    "    df_train = pd.read_csv(os.path.join(data_dir, 'EdgeIIot_train_100k.csv'), low_memory=False)\n",
    "elif AUGMENTATION == 'SMOTE':\n",
    "    df_train = pd.read_csv(os.path.join(data_dir, 'EdgeIIot_train_100k_SMOTE.csv'), low_memory=False)\n",
    "elif AUGMENTATION == 'SMOTE-NC':\n",
    "    df_train = pd.read_csv(os.path.join(data_dir, 'EdgeIIot_train_100k_SMOTE_NC.csv'), low_memory=False)\n",
    "elif AUGMENTATION == 'RealTabFormer':\n",
    "    df_train = pd.read_csv(os.path.join(data_dir, 'EdgeIIot_train_100k_RealTabFormer.csv'), low_memory=False)\n",
    "elif AUGMENTATION == 'GReaT':\n",
    "    df_train = pd.read_csv(os.path.join(data_dir, 'EdgeIIot_train_100k_GReaT.csv'), low_memory=False)\n",
    "else:\n",
    "    raise ValueError(\"AUGMENTATION option not recognized. Please choose between 'None', 'SMOTE', 'SMOTE-NC', 'RealTabFormer', or 'GReaT'.\")\n",
    "\n",
    "'Test data for all datasets'\n",
    "df_test = pd.read_csv(os.path.join(data_dir, 'EdgeIIot_test.csv'), low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns mbtcp.unit_id and mbtcp.trans_id from train and test data    \n",
    "df_train = df_train.drop(['mbtcp.unit_id', 'mbtcp.trans_id'], axis=1)\n",
    "df_test = df_test.drop(['mbtcp.unit_id', 'mbtcp.trans_id'], axis=1)\n",
    "\n",
    "# Creates X_train, y_train\n",
    "X_train = df_train.drop(['Attack_label', 'Attack_type'], axis=1)\n",
    "y_train = df_train['Attack_type']\n",
    "\n",
    "# Creates X_test, y_test\n",
    "X_test = df_test.drop(['Attack_label', 'Attack_type'], axis=1)\n",
    "y_test = df_test['Attack_type']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One-hot encoding categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (536515, 83), X_test shape: (381934, 83)\n"
     ]
    }
   ],
   "source": [
    "# check if there is categorical data in the dataset\n",
    "if X_train.select_dtypes(include=\"object\").columns.size > 0:\n",
    "    \n",
    "    # Concatenate X_train and X_test to ensure consistent encoding for both\n",
    "    concatenated_data = pd.concat([X_train, X_test], axis=0)\n",
    "\n",
    "    # Extract categorical features\n",
    "    categorical_features = concatenated_data.select_dtypes(include=\"object\").columns\n",
    "\n",
    "    # Extract indices of categorical features\n",
    "    cat_idxs = [concatenated_data.columns.get_loc(col) for col in categorical_features]\n",
    "\n",
    "    # Find number of unique values in each categorical column\n",
    "    cat_dims = [len(concatenated_data[col].unique()) for col in categorical_features]\n",
    "\n",
    "    # One-hot encode categorical features for both X_train and X_test\n",
    "    concatenated_data_encoded = pd.get_dummies(concatenated_data, \n",
    "                                               columns=categorical_features, \n",
    "                                               drop_first=True, \n",
    "                                               dtype='int8')\n",
    "\n",
    "    # Split the data back into X_train and X_test\n",
    "    X_train = concatenated_data_encoded.iloc[:len(X_train)]\n",
    "    X_test = concatenated_data_encoded.iloc[len(X_train):]\n",
    "    \n",
    "    print(f'X_train shape: {X_train.shape}, X_test shape: {X_test.shape}')\n",
    "    \n",
    "\n",
    "\n",
    "# if AUGMENTATION == 'None':\n",
    "#     # Concatenate X_train and X_test to ensure consistent encoding for both\n",
    "#     concatenated_data = pd.concat([X_train, X_test], axis=0)\n",
    "\n",
    "#     # Extract categorical features\n",
    "#     categorical_features = concatenated_data.select_dtypes(include=\"object\").columns\n",
    "\n",
    "#     # Get the unique values of all categorical columns\n",
    "#     for col in concatenated_data[categorical_features].columns:\n",
    "#         unique_values = concatenated_data[col].unique()\n",
    "#         print(f'{col}: \\n{unique_values}\\n')\n",
    "\n",
    "#     # One-hot encode categorical features for both X_train and X_test\n",
    "#     concatenated_data_encoded = pd.get_dummies(concatenated_data, \n",
    "#                                                columns=categorical_features, \n",
    "#                                                drop_first=True, \n",
    "#                                                dtype='int8')\n",
    "\n",
    "#     # Split the data back into X_train and X_test\n",
    "#     X_train = concatenated_data_encoded.iloc[:len(X_train)]\n",
    "#     X_test = concatenated_data_encoded.iloc[len(X_train):]\n",
    "    \n",
    "#     print(f'X_train shape: {X_train.shape}, X_test shape: {X_test.shape}')\n",
    "    \n",
    "#     def get_unique_values(df, columns):\n",
    "#         unique_values = df[columns].apply(lambda x: ''.join(x.astype(str)), axis=1).unique()\n",
    "#         unique_values.sort()\n",
    "#         return unique_values\n",
    "\n",
    "#     http_referer_columns = [col for col in X_train.columns if 'http.referer' in col]\n",
    "#     http_request_version_columns = [col for col in X_train.columns if 'http.request.version' in col]\n",
    "#     dns_qry_name_len_columns = [col for col in X_train.columns if 'dns.qry.name.len' in col]\n",
    "#     mqtt_conack_flags_columns = [col for col in X_train.columns if 'mqtt.conack.flags' in col]\n",
    "#     mqtt_protoname_columns = [col for col in X_train.columns if 'mqtt.protoname' in col]\n",
    "#     http_request_method_columns = [col for col in X_train.columns if 'http.request.method' in col]\n",
    "\n",
    "#     unique_values_http_referer = get_unique_values(X_train, http_referer_columns)\n",
    "#     unique_values_http_request_version = get_unique_values(X_train, http_request_version_columns)\n",
    "#     unique_values_dns_qry_name_len = get_unique_values(X_train, dns_qry_name_len_columns)\n",
    "#     unique_values_mqtt_conack_flags = get_unique_values(X_train, mqtt_conack_flags_columns)\n",
    "#     unique_values_mqtt_protoname = get_unique_values(X_train, mqtt_protoname_columns)\n",
    "\n",
    "#     # Apply the same function to X_test\n",
    "#     unique_values_http_referer_test = get_unique_values(X_test, http_referer_columns)\n",
    "#     unique_values_http_request_version_test = get_unique_values(X_test, http_request_version_columns)\n",
    "#     unique_values_dns_qry_name_len_test = get_unique_values(X_test, dns_qry_name_len_columns)\n",
    "#     unique_values_mqtt_conack_flags_test = get_unique_values(X_test, mqtt_conack_flags_columns)\n",
    "#     unique_values_mqtt_protoname_test = get_unique_values(X_test, mqtt_protoname_columns)\n",
    "    \n",
    "#     # Join the unique values from both train and test data and print them\n",
    "#     unique_values_http_referer = np.unique(np.concatenate((unique_values_http_referer, unique_values_http_referer_test)))\n",
    "#     unique_values_http_request_version = np.unique(np.concatenate((unique_values_http_request_version, unique_values_http_request_version_test)))\n",
    "#     unique_values_dns_qry_name_len = np.unique(np.concatenate((unique_values_dns_qry_name_len, unique_values_dns_qry_name_len_test)))\n",
    "#     unique_values_mqtt_conack_flags = np.unique(np.concatenate((unique_values_mqtt_conack_flags, unique_values_mqtt_conack_flags_test)))\n",
    "#     unique_values_mqtt_protoname = np.unique(np.concatenate((unique_values_mqtt_protoname, unique_values_mqtt_protoname_test)))\n",
    "\n",
    "#     print(f'Unique values for http.referer: \\n{unique_values_http_referer}\\n')\n",
    "#     print(f'Unique values for http.request.version: \\n{unique_values_http_request_version}\\n')\n",
    "#     print(f'Unique values for dns.qry.name.len: \\n{unique_values_dns_qry_name_len}\\n')\n",
    "#     print(f'Unique values for mqtt.conack.flags: \\n{unique_values_mqtt_conack_flags}\\n')\n",
    "#     print(f'Unique values for mqtt.protoname: \\n{unique_values_mqtt_protoname}\\n')\n",
    "    \n",
    "#     # check if X_train and X_test have categorical features\n",
    "#     print(f'X_train categorical features: {X_train.select_dtypes(include=\"object\").columns}')\n",
    "#     print(f'X_test categorical features: {X_test.select_dtypes(include=\"object\").columns}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid = False\n",
    "\n",
    "if valid == True:\n",
    "    def get_unique_values(df, columns):\n",
    "        unique_values = df[columns].apply(lambda x: ''.join(x.astype(str)), axis=1).unique()\n",
    "        unique_values.sort()\n",
    "        return unique_values\n",
    "\n",
    "    http_referer_columns = [col for col in X_train.columns if 'http.referer' in col]\n",
    "    http_request_version_columns = [col for col in X_train.columns if 'http.request.version' in col]\n",
    "    dns_qry_name_len_columns = [col for col in X_train.columns if 'dns.qry.name.len' in col]\n",
    "    mqtt_conack_flags_columns = [col for col in X_train.columns if 'mqtt.conack.flags' in col]\n",
    "    mqtt_protoname_columns = [col for col in X_train.columns if 'mqtt.protoname' in col]\n",
    "    http_request_method_columns = [col for col in X_train.columns if 'http.request.method' in col]\n",
    "\n",
    "    unique_values_http_referer = get_unique_values(X_train, http_referer_columns)\n",
    "    unique_values_http_request_version = get_unique_values(X_train, http_request_version_columns)\n",
    "    unique_values_dns_qry_name_len = get_unique_values(X_train, dns_qry_name_len_columns)\n",
    "    unique_values_mqtt_conack_flags = get_unique_values(X_train, mqtt_conack_flags_columns)\n",
    "    unique_values_mqtt_protoname = get_unique_values(X_train, mqtt_protoname_columns)\n",
    "\n",
    "    # Apply the same function to X_test\n",
    "    unique_values_http_referer_test = get_unique_values(X_test, http_referer_columns)\n",
    "    unique_values_http_request_version_test = get_unique_values(X_test, http_request_version_columns)\n",
    "    unique_values_dns_qry_name_len_test = get_unique_values(X_test, dns_qry_name_len_columns)\n",
    "    unique_values_mqtt_conack_flags_test = get_unique_values(X_test, mqtt_conack_flags_columns)\n",
    "    unique_values_mqtt_protoname_test = get_unique_values(X_test, mqtt_protoname_columns)\n",
    "    \n",
    "    # Join the unique values from both train and test data and print them\n",
    "    unique_values_http_referer = np.unique(np.concatenate((unique_values_http_referer, unique_values_http_referer_test)))\n",
    "    unique_values_http_request_version = np.unique(np.concatenate((unique_values_http_request_version, unique_values_http_request_version_test)))\n",
    "    unique_values_dns_qry_name_len = np.unique(np.concatenate((unique_values_dns_qry_name_len, unique_values_dns_qry_name_len_test)))\n",
    "    unique_values_mqtt_conack_flags = np.unique(np.concatenate((unique_values_mqtt_conack_flags, unique_values_mqtt_conack_flags_test)))\n",
    "    unique_values_mqtt_protoname = np.unique(np.concatenate((unique_values_mqtt_protoname, unique_values_mqtt_protoname_test)))\n",
    "\n",
    "    print(f'Unique values for http.referer: \\n{unique_values_http_referer}\\n')\n",
    "    print(f'Unique values for http.request.version: \\n{unique_values_http_request_version}\\n')\n",
    "    print(f'Unique values for dns.qry.name.len: \\n{unique_values_dns_qry_name_len}\\n')\n",
    "    print(f'Unique values for mqtt.conack.flags: \\n{unique_values_mqtt_conack_flags}\\n')\n",
    "    print(f'Unique values for mqtt.protoname: \\n{unique_values_mqtt_protoname}\\n')\n",
    "    \n",
    "    # check if X_train and X_test have categorical features\n",
    "    print(f'X_train categorical features: {X_train.select_dtypes(include=\"object\").columns}')\n",
    "    print(f'X_test categorical features: {X_test.select_dtypes(include=\"object\").columns}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # AQUI Categorical columns in df_train\n",
    "# categorical_columns = [f for f in features if f in df_train.select_dtypes(include=\"object\").columns]\n",
    "\n",
    "# # Concatenate X_train and X_test\n",
    "# X_comb = pd.concat([X_train[categorical_columns], X_test[categorical_columns]], axis=0)\n",
    "\n",
    "# # Apply one-hot encoding (get_dummies)\n",
    "# X_comb_enc = pd.get_dummies(X_comb, dtype='int8')\n",
    "\n",
    "# # Split back into X_train and X_test\n",
    "# X_train_enc, X_test_enc = train_test_split(\n",
    "#     X_comb_enc, test_size=len(X_test), random_state=42)\n",
    "\n",
    "# # Print the shape of X_train_enc and X_test_enc\n",
    "# print(f'X_train_enc shape: {X_train_enc.shape}, X_test_enc shape: {X_test_enc.shape}')\n",
    "\n",
    "\n",
    "# # converts X_train and y_train to numpy arrays\n",
    "# X_train = df_train[features]\n",
    "# y_train = df_train[\"Attack_type\"]\n",
    "\n",
    "# # converts X_test and y_test to numpy arrays\n",
    "# X_test = df_test[features]\n",
    "# y_test = df_test[\"Attack_type\"]\n",
    "\n",
    "# # size of X_train, y_train  X_test, y_test\n",
    "# print(f'X_train shape: {X_train.shape}, y_train shape: {y_train.shape}')\n",
    "# print(f'X_test shape: {X_test.shape}, y_test shape: {y_test.shape}')\n",
    "# print(cat_idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack_type and encoded labels:\n",
      "\n",
      "Backdoor                0\n",
      "DDoS_HTTP               1\n",
      "DDoS_ICMP               2\n",
      "DDoS_TCP                3\n",
      "DDoS_UDP                4\n",
      "Fingerprinting          5\n",
      "MITM                    6\n",
      "Normal                  7\n",
      "Password                8\n",
      "Port_Scanning           9\n",
      "Ransomware              10\n",
      "SQL_injection           11\n",
      "Uploading               12\n",
      "Vulnerability_scanner   13\n",
      "XSS                     14\n"
     ]
    }
   ],
   "source": [
    "# instantiate the label encoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# fit and encode the training labels\n",
    "y_train = le.fit_transform(y_train)\n",
    "\n",
    "# encode the test labels\n",
    "y_test = le.transform(y_test)\n",
    "\n",
    "print('Attack_type and encoded labels:\\n')\n",
    "for i, label in enumerate(le.classes_):\n",
    "    print(f'{label:23s} {i:d}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # embedding dimension for each categorical column\n",
    "# cat_emb_dim = 10 \n",
    "\n",
    "# # initialize embedder \n",
    "# cat_embedder = TabNetPretrainer(cat_dims, cat_emb_dim, cat_idxs)\n",
    "\n",
    "# # instantiate TabNetClassifier model\n",
    "# tabnet = TabNetClassifier(device_name = DEVICE,\n",
    "#                           cat_idxs=cat_idxs,\n",
    "#                           cat_dims=cat_dims,\n",
    "#                           cat_emb_dim=cat_emb_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/tiagociic/Projectos/inovmineral/project/notebooks/3_tabnet_evaluation.ipynb Cell 17\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/tiagociic/Projectos/inovmineral/project/notebooks/3_tabnet_evaluation.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# tabnet = TabNetClassifier(n_d=64, \u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/tiagociic/Projectos/inovmineral/project/notebooks/3_tabnet_evaluation.ipynb#X21sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m#                           n_a=64, \u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/tiagociic/Projectos/inovmineral/project/notebooks/3_tabnet_evaluation.ipynb#X21sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m#                           n_steps=5,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tiagociic/Projectos/inovmineral/project/notebooks/3_tabnet_evaluation.ipynb#X21sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tiagociic/Projectos/inovmineral/project/notebooks/3_tabnet_evaluation.ipynb#X21sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m# pytorch_tabnet default parameters default parameters except for cat_emb_dim, which is set to 10\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/tiagociic/Projectos/inovmineral/project/notebooks/3_tabnet_evaluation.ipynb#X21sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m tabnet \u001b[39m=\u001b[39m TabNetClassifier(cat_idxs\u001b[39m=\u001b[39;49mcat_idxs,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tiagociic/Projectos/inovmineral/project/notebooks/3_tabnet_evaluation.ipynb#X21sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m                           cat_dims\u001b[39m=\u001b[39;49mcat_dims,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tiagociic/Projectos/inovmineral/project/notebooks/3_tabnet_evaluation.ipynb#X21sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m                           cat_emb_dim\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tiagociic/Projectos/inovmineral/project/notebooks/3_tabnet_evaluation.ipynb#X21sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m                           )\n",
      "File \u001b[0;32m<string>:29\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, n_d, n_a, n_steps, gamma, cat_idxs, cat_dims, cat_emb_dim, n_independent, n_shared, epsilon, momentum, lambda_sparse, seed, clip_value, verbose, optimizer_fn, optimizer_params, scheduler_fn, scheduler_params, mask_type, input_dim, output_dim, device_name, n_shared_decoder, n_indep_decoder, grouped_features)\u001b[0m\n",
      "File \u001b[0;32m~/Projectos/inovmineral/lib/python3.11/site-packages/pytorch_tabnet/tab_model.py:13\u001b[0m, in \u001b[0;36mTabNetClassifier.__post_init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__post_init__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m---> 13\u001b[0m     \u001b[39msuper\u001b[39;49m(TabNetClassifier, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m__post_init__()\n\u001b[1;32m     14\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_task \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mclassification\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     15\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_default_loss \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39mcross_entropy\n",
      "File \u001b[0;32m~/Projectos/inovmineral/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:78\u001b[0m, in \u001b[0;36mTabModel.__post_init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size \u001b[39m=\u001b[39m \u001b[39m1024\u001b[39m\n\u001b[1;32m     76\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvirtual_batch_size \u001b[39m=\u001b[39m \u001b[39m128\u001b[39m\n\u001b[0;32m---> 78\u001b[0m torch\u001b[39m.\u001b[39;49mmanual_seed(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mseed)\n\u001b[1;32m     79\u001b[0m \u001b[39m# Defining device\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdevice(define_device(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice_name))\n",
      "File \u001b[0;32m~/Projectos/inovmineral/lib/python3.11/site-packages/torch/random.py:40\u001b[0m, in \u001b[0;36mmanual_seed\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcuda\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39m_is_in_bad_fork():\n\u001b[0;32m---> 40\u001b[0m     torch\u001b[39m.\u001b[39;49mcuda\u001b[39m.\u001b[39;49mmanual_seed_all(seed)\n\u001b[1;32m     42\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmps\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39mmps\u001b[39m.\u001b[39m_is_in_bad_fork():\n",
      "File \u001b[0;32m~/Projectos/inovmineral/lib/python3.11/site-packages/torch/cuda/random.py:124\u001b[0m, in \u001b[0;36mmanual_seed_all\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m    121\u001b[0m         default_generator \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mdefault_generators[i]\n\u001b[1;32m    122\u001b[0m         default_generator\u001b[39m.\u001b[39mmanual_seed(seed)\n\u001b[0;32m--> 124\u001b[0m _lazy_call(cb, seed_all\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/Projectos/inovmineral/lib/python3.11/site-packages/torch/cuda/__init__.py:229\u001b[0m, in \u001b[0;36m_lazy_call\u001b[0;34m(callable, **kwargs)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_lazy_call\u001b[39m(\u001b[39mcallable\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    228\u001b[0m     \u001b[39mif\u001b[39;00m is_initialized():\n\u001b[0;32m--> 229\u001b[0m         \u001b[39mcallable\u001b[39;49m()\n\u001b[1;32m    230\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    231\u001b[0m         \u001b[39m# TODO(torch_deploy): this accesses linecache, which attempts to read the\u001b[39;00m\n\u001b[1;32m    232\u001b[0m         \u001b[39m# file system to get traceback info. Patch linecache or do something\u001b[39;00m\n\u001b[1;32m    233\u001b[0m         \u001b[39m# else here if this ends up being important.\u001b[39;00m\n\u001b[1;32m    234\u001b[0m         \u001b[39mglobal\u001b[39;00m _lazy_seed_tracker\n",
      "File \u001b[0;32m~/Projectos/inovmineral/lib/python3.11/site-packages/torch/cuda/random.py:122\u001b[0m, in \u001b[0;36mmanual_seed_all.<locals>.cb\u001b[0;34m()\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(device_count()):\n\u001b[1;32m    121\u001b[0m     default_generator \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mdefault_generators[i]\n\u001b[0;32m--> 122\u001b[0m     default_generator\u001b[39m.\u001b[39;49mmanual_seed(seed)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "# tabnet = TabNetClassifier(n_d=64, \n",
    "#                           n_a=64, \n",
    "#                           n_steps=5,\n",
    "#                           gamma=1.5,\n",
    "#                           cat_idxs=cat_idxs,\n",
    "#                           cat_dims=cat_dims,\n",
    "#                           cat_emb_dim=10,\n",
    "#                           lambda_sparse=1e-4, \n",
    "#                           momentum=0.3, \n",
    "#                           clip_value=2.,\n",
    "#                           optimizer_params=dict(lr=2e-2),\n",
    "#                           scheduler_params = {\"gamma\": 0.95, \"step_size\": 20},\n",
    "#                           scheduler_fn=torch.optim.lr_scheduler.StepLR, \n",
    "#                           )\n",
    "\n",
    "\n",
    "# pytorch_tabnet default parameters default parameters except for cat_emb_dim, which is set to 10\n",
    "tabnet = TabNetClassifier(cat_idxs=cat_idxs,\n",
    "                          cat_dims=cat_dims,\n",
    "                          cat_emb_dim=10,\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TabModel(n_d: int = 8,\n",
    "#         n_a: int = 8, \n",
    "#         n_steps: int = 3, \n",
    "#         gamma: float = 1.3, \n",
    "#         cat_idxs: List[int] = <factory>, \n",
    "#         cat_dims: List[int] = <factory>, \n",
    "#         cat_emb_dim: int = 1, \n",
    "#         n_independent: int = 2, \n",
    "#         n_shared: int = 2, \n",
    "#         epsilon: float = 1e-15, \n",
    "#         momentum: float = 0.02, \n",
    "#         lambda_sparse: float = 0.001, \n",
    "#         seed: int = 0, \n",
    "#         clip_value: int = 1, \n",
    "#         verbose: int = 1, \n",
    "#         optimizer_fn: Any = <class 'torch.optim.adam.Adam'>, \n",
    "#         optimizer_params: Dict = <factory>, \n",
    "#         scheduler_fn: Any = None, \n",
    "#         scheduler_params: Dict = <factory>, \n",
    "#         mask_type: str = 'sparsemax', \n",
    "#         input_dim: int = None, \n",
    "#         output_dim: int = None, \n",
    "#         device_name: str = 'auto', \n",
    "#         n_shared_decoder: int = 1, \n",
    "#         n_indep_decoder: int = 1, \n",
    "#         grouped_features: List[List[int]] = <factory>\n",
    "#         )\n",
    "\n",
    "# fit(X_train, \n",
    "#     y_train, \n",
    "#     eval_set=None, \n",
    "#     eval_name=None, \n",
    "#     eval_metric=None, \n",
    "#     loss_fn=None, \n",
    "#     weights=0, \n",
    "#     max_epochs=100, \n",
    "#     patience=10, \n",
    "#     batch_size=1024, \n",
    "#     virtual_batch_size=128, \n",
    "#     num_workers=0, \n",
    "#     drop_last=True, \n",
    "#     callbacks=None, \n",
    "#     pin_memory=True, \n",
    "#     from_unsupervised=None, \n",
    "#     warm_start=False, \n",
    "#     augmentations=None, \n",
    "#     compute_importance=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((536515, 83), (536515,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tiagociic/Projectos/inovmineral/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [27,0,0], thread: [32,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [27,0,0], thread: [33,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [27,0,0], thread: [34,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [27,0,0], thread: [35,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [27,0,0], thread: [36,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [27,0,0], thread: [37,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [27,0,0], thread: [38,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [27,0,0], thread: [39,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [27,0,0], thread: [40,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [27,0,0], thread: [41,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [27,0,0], thread: [42,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1292: indexSelectLargeIndex: block: [27,0,0], thread: [43,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/tiagociic/Projectos/inovmineral/project/notebooks/3_tabnet_evaluation.ipynb Cell 21\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/tiagociic/Projectos/inovmineral/project/notebooks/3_tabnet_evaluation.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# pytorch_tabnet default parameters\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/tiagociic/Projectos/inovmineral/project/notebooks/3_tabnet_evaluation.ipynb#X23sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m tabnet\u001b[39m.\u001b[39;49mfit(X_train\u001b[39m=\u001b[39;49mX_train\u001b[39m.\u001b[39;49mvalues, \n\u001b[1;32m      <a href='vscode-notebook-cell:/home/tiagociic/Projectos/inovmineral/project/notebooks/3_tabnet_evaluation.ipynb#X23sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m            y_train\u001b[39m=\u001b[39;49my_train,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/tiagociic/Projectos/inovmineral/project/notebooks/3_tabnet_evaluation.ipynb#X23sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m            augmentations\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/tiagociic/Projectos/inovmineral/project/notebooks/3_tabnet_evaluation.ipynb#X23sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m            )\n",
      "File \u001b[0;32m~/Projectos/inovmineral/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:258\u001b[0m, in \u001b[0;36mTabModel.fit\u001b[0;34m(self, X_train, y_train, eval_set, eval_name, eval_metric, loss_fn, weights, max_epochs, patience, batch_size, virtual_batch_size, num_workers, drop_last, callbacks, pin_memory, from_unsupervised, warm_start, augmentations, compute_importance)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[39mfor\u001b[39;00m epoch_idx \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_epochs):\n\u001b[1;32m    254\u001b[0m \n\u001b[1;32m    255\u001b[0m     \u001b[39m# Call method on_epoch_begin for all callbacks\u001b[39;00m\n\u001b[1;32m    256\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_callback_container\u001b[39m.\u001b[39mon_epoch_begin(epoch_idx)\n\u001b[0;32m--> 258\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_epoch(train_dataloader)\n\u001b[1;32m    260\u001b[0m     \u001b[39m# Apply predict epoch to all eval sets\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[39mfor\u001b[39;00m eval_name, valid_dataloader \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(eval_names, valid_dataloaders):\n",
      "File \u001b[0;32m~/Projectos/inovmineral/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:489\u001b[0m, in \u001b[0;36mTabModel._train_epoch\u001b[0;34m(self, train_loader)\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[39mfor\u001b[39;00m batch_idx, (X, y) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader):\n\u001b[1;32m    487\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_callback_container\u001b[39m.\u001b[39mon_batch_begin(batch_idx)\n\u001b[0;32m--> 489\u001b[0m     batch_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_batch(X, y)\n\u001b[1;32m    491\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_callback_container\u001b[39m.\u001b[39mon_batch_end(batch_idx, batch_logs)\n\u001b[1;32m    493\u001b[0m epoch_logs \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mlr\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimizer\u001b[39m.\u001b[39mparam_groups[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mlr\u001b[39m\u001b[39m\"\u001b[39m]}\n",
      "File \u001b[0;32m~/Projectos/inovmineral/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:527\u001b[0m, in \u001b[0;36mTabModel._train_batch\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[39mfor\u001b[39;00m param \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnetwork\u001b[39m.\u001b[39mparameters():\n\u001b[1;32m    525\u001b[0m     param\u001b[39m.\u001b[39mgrad \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 527\u001b[0m output, M_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnetwork(X)\n\u001b[1;32m    529\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_loss(output, y)\n\u001b[1;32m    530\u001b[0m \u001b[39m# Add the overall sparsity loss\u001b[39;00m\n",
      "File \u001b[0;32m~/Projectos/inovmineral/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Projectos/inovmineral/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Projectos/inovmineral/lib/python3.11/site-packages/pytorch_tabnet/tab_network.py:615\u001b[0m, in \u001b[0;36mTabNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    614\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m--> 615\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membedder(x)\n\u001b[1;32m    616\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtabnet(x)\n",
      "File \u001b[0;32m~/Projectos/inovmineral/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Projectos/inovmineral/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Projectos/inovmineral/lib/python3.11/site-packages/pytorch_tabnet/tab_network.py:894\u001b[0m, in \u001b[0;36mEmbeddingGenerator.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    892\u001b[0m         cat_feat_counter \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    893\u001b[0m \u001b[39m# concat\u001b[39;00m\n\u001b[0;32m--> 894\u001b[0m post_embeddings \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mcat(cols, dim\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m    895\u001b[0m \u001b[39mreturn\u001b[39;00m post_embeddings\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "# pytorch_tabnet default parameters\n",
    "tabnet.fit(X_train=X_train.values, \n",
    "           y_train=y_train,\n",
    "           augmentations=None,\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 8, 4, ..., 7, 7, 7])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NOTA: NÃO É nËCESSÄRIO APAGAR COLUNAS CATEGÓRICAS DE X_TRAIN E X_TEST SE SE IDENTIFICAREM OS ÍNDICES DAS COLUNAS CATEGÓRICAS E SE SE UTILIZAR O PARÂMETRO cat_idxs=cat_idxs NO MODELO TABNETCLASSIFIER\n",
    "# REVER OUTROS NOTEBOOKS!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved model at checkpoints/tabnet_none.zip\n"
     ]
    }
   ],
   "source": [
    "saved_filename = tabnet.save_model('checkpoints/tabnet_none')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = tabnet.predict(X_test_enc.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Evaluation Metrics\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Accuracy: 0.83\n",
      "Precision (macro): 0.88\n",
      "Recall (macro): 0.30\n",
      "F1 (macro): 0.22\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~\n"
     ]
    }
   ],
   "source": [
    "accuracy = metrics.accuracy_score(y_test, predictions)\n",
    "precision_w = metrics.precision_score(y_test, predictions, average='weighted', zero_division=1)\n",
    "recall_w = metrics.recall_score(y_test, predictions, average='weighted')\n",
    "f1_score_w = metrics.f1_score(y_test, predictions, average='weighted')\n",
    "precision_m = metrics.precision_score(y_test, predictions, average='macro', zero_division=1)\n",
    "recall_m = metrics.recall_score(y_test, predictions, average='macro')\n",
    "f1_score_m = metrics.f1_score(y_test, predictions, average='macro')\n",
    "\n",
    "print(\"Model Evaluation Metrics\")\n",
    "print(\"~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "print(\"Accuracy: {:.2f}\".format(accuracy))\n",
    "print(\"Precision (macro): {:.2f}\".format(precision_m))\n",
    "print(\"Recall (macro): {:.2f}\".format(recall_m))\n",
    "print(\"F1 (macro): {:.2f}\".format(f1_score_m))\n",
    "print(\"Precision (weighted): {:.2f}\".format(precision_w))\n",
    "print(\"Recall (weighted): {:.2f}\".format(recall_w))\n",
    "print(\"F1 (weighted): {:.2f}\".format(f1_score_w))\n",
    "print(\"~~~~~~~~~~~~~~~~~~~~~~~~~\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Metrics Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary for results\n",
    "results = {\n",
    "    \"model\": \"tabnet\",\n",
    "    \"augmentations\": AUGMENTATION,\n",
    "    \"timestamp\": datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    \"accuracy\": accuracy,\n",
    "    \"precision\": precision,\n",
    "    \"recall\": recall,\n",
    "    \"f1\": f1_score\n",
    "    }\n",
    "\n",
    "# save results to csv   \n",
    "utils.save_results_to_csv([results], '../results/metrics/tabnet.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>Backdoor</th>\n",
       "      <th>DDoS_HTTP</th>\n",
       "      <th>DDoS_ICMP</th>\n",
       "      <th>DDoS_TCP</th>\n",
       "      <th>DDoS_UDP</th>\n",
       "      <th>Fingerprinting</th>\n",
       "      <th>MITM</th>\n",
       "      <th>Normal</th>\n",
       "      <th>Password</th>\n",
       "      <th>Port_Scanning</th>\n",
       "      <th>Ransomware</th>\n",
       "      <th>SQL_injection</th>\n",
       "      <th>Uploading</th>\n",
       "      <th>Vulnerability_scanner</th>\n",
       "      <th>XSS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Backdoor</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4782</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DDoS_HTTP</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9628</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DDoS_ICMP</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13501</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DDoS_TCP</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10009</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DDoS_UDP</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24601</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fingerprinting</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MITM</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Normal</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>272775</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Password</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10108</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Port_Scanning</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4062</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ransomware</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1926</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SQL_injection</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10071</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Uploading</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7273</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vulnerability_scanner</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9939</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XSS</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3035</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted              Backdoor  DDoS_HTTP  DDoS_ICMP  DDoS_TCP  DDoS_UDP  \\\n",
       "Actual                                                                      \n",
       "Backdoor                      0          0          0         0      4782   \n",
       "DDoS_HTTP                     0          0          0         0         0   \n",
       "DDoS_ICMP                     0          0          0         0     13501   \n",
       "DDoS_TCP                      0          0          0         0     10009   \n",
       "DDoS_UDP                      0          0          0         0     24601   \n",
       "Fingerprinting                0          0          0         0       146   \n",
       "MITM                          0          0          0         0         0   \n",
       "Normal                        0          0          0         0         0   \n",
       "Password                      0          0          0         0         0   \n",
       "Port_Scanning                 0          0          0         0      4062   \n",
       "Ransomware                    0          0          0         0      1926   \n",
       "SQL_injection                 0          0          0         0         0   \n",
       "Uploading                     0          0          0         0         0   \n",
       "Vulnerability_scanner         0          0          0         0         0   \n",
       "XSS                           0          0          0         0         0   \n",
       "\n",
       "Predicted              Fingerprinting  MITM  Normal  Password  Port_Scanning  \\\n",
       "Actual                                                                         \n",
       "Backdoor                            0     0       0         0              0   \n",
       "DDoS_HTTP                           0     0       0         0              0   \n",
       "DDoS_ICMP                           0     0       0         0              0   \n",
       "DDoS_TCP                            0     0       0         0              0   \n",
       "DDoS_UDP                            0     0       0         0              0   \n",
       "Fingerprinting                      0     0       0         0              0   \n",
       "MITM                                0    33       0         0              0   \n",
       "Normal                              0     0  272775         0              0   \n",
       "Password                            0     0       0         0              0   \n",
       "Port_Scanning                       0     0       0         0              0   \n",
       "Ransomware                          0     0       0         0              0   \n",
       "SQL_injection                       0     0       0         0              0   \n",
       "Uploading                           0     0       0         0              0   \n",
       "Vulnerability_scanner               0     0       0         0              0   \n",
       "XSS                                 0     0       0         0              0   \n",
       "\n",
       "Predicted              Ransomware  SQL_injection  Uploading  \\\n",
       "Actual                                                        \n",
       "Backdoor                        0              0          0   \n",
       "DDoS_HTTP                       0              0          0   \n",
       "DDoS_ICMP                       0              0          0   \n",
       "DDoS_TCP                        0              0          0   \n",
       "DDoS_UDP                        0              0          0   \n",
       "Fingerprinting                  0              0          0   \n",
       "MITM                            0              0          0   \n",
       "Normal                          0              0          0   \n",
       "Password                        0          10108          0   \n",
       "Port_Scanning                   0              0          0   \n",
       "Ransomware                      0              0          0   \n",
       "SQL_injection                   0          10071          0   \n",
       "Uploading                       0           7273          0   \n",
       "Vulnerability_scanner           0              1          0   \n",
       "XSS                             0              0          0   \n",
       "\n",
       "Predicted              Vulnerability_scanner  XSS  \n",
       "Actual                                             \n",
       "Backdoor                                   0    0  \n",
       "DDoS_HTTP                               9628    0  \n",
       "DDoS_ICMP                                  0    0  \n",
       "DDoS_TCP                                   0    0  \n",
       "DDoS_UDP                                   0    0  \n",
       "Fingerprinting                             0    0  \n",
       "MITM                                      43    0  \n",
       "Normal                                     1    0  \n",
       "Password                                   0    0  \n",
       "Port_Scanning                              0    0  \n",
       "Ransomware                                 0    0  \n",
       "SQL_injection                              0    0  \n",
       "Uploading                                  0    0  \n",
       "Vulnerability_scanner                   9939    0  \n",
       "XSS                                     3035    0  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_mat = metrics.confusion_matrix(y_test, predictions)\n",
    "\n",
    "attack_labels = ['Backdoor', 'DDoS_HTTP', 'DDoS_ICMP', 'DDoS_TCP', 'DDoS_UDP', \n",
    "'Fingerprinting', 'MITM', 'Normal', 'Password', 'Port_Scanning', 'Ransomware', \n",
    "'SQL_injection', 'Uploading', 'Vulnerability_scanner', 'XSS']\n",
    "\n",
    "# Create a dataframe from the confusion matrix\n",
    "conf_mat_df = pd.DataFrame(conf_mat, \n",
    "                            index = attack_labels, \n",
    "                            columns = attack_labels)\n",
    "conf_mat_df.index.name = 'Actual'\n",
    "conf_mat_df.columns.name = 'Predicted'\n",
    "\n",
    "# Save the confusion matrix\n",
    "conf_mat_df.to_csv(f\"../results/conf_matrix/{results['model']}_{results['augmentations']}.csv\")\n",
    "conf_mat_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_augment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
